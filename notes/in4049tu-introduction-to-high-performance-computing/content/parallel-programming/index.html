<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="ie=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=author content>
<meta name=description content="For distributed memory MPI is used as programming model, with shared memory OpenMP is used, and for GPUs CUDA is used.
MPI Program With MPI programs, the processes that execute the program all have their own local data. Typically one process will be on one core, each process can then access its own data locally and use message passing to get other data from other cores. In MPI programming the environment needs to be initialized before it can be used, and finalized when it&amp;rsquo;s done.">
<meta name=keywords content>
<meta name=robots content="noodp">
<meta name=theme-color content>
<link rel=canonical href=https://nicktehrany.github.io/notes/in4049tu-introduction-to-high-performance-computing/content/parallel-programming/>
<title>
Parallel Programming
</title>
<link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css rel=stylesheet type=text/css>
<link rel=stylesheet href=/main.89fa80e2143f71bd5c96a7c94e531dec3276a367e22f87e74a76026ab64680bf.css>
<meta itemprop=name content="Parallel Programming">
<meta itemprop=description content="For distributed memory MPI is used as programming model, with shared memory OpenMP is used, and for GPUs CUDA is used.
MPI Program With MPI programs, the processes that execute the program all have their own local data. Typically one process will be on one core, each process can then access its own data locally and use message passing to get other data from other cores. In MPI programming the environment needs to be initialized before it can be used, and finalized when it&rsquo;s done."><meta itemprop=datePublished content="2021-09-14T15:50:41+02:00">
<meta itemprop=dateModified content="2021-09-14T15:50:41+02:00">
<meta itemprop=wordCount content="332"><meta itemprop=image content="https://nicktehrany.github.io">
<meta itemprop=keywords content>
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://nicktehrany.github.io">
<meta name=twitter:title content="Parallel Programming">
<meta name=twitter:description content="For distributed memory MPI is used as programming model, with shared memory OpenMP is used, and for GPUs CUDA is used.
MPI Program With MPI programs, the processes that execute the program all have their own local data. Typically one process will be on one core, each process can then access its own data locally and use message passing to get other data from other cores. In MPI programming the environment needs to be initialized before it can be used, and finalized when it&rsquo;s done.">
<meta property="og:title" content="Parallel Programming">
<meta property="og:description" content="For distributed memory MPI is used as programming model, with shared memory OpenMP is used, and for GPUs CUDA is used.
MPI Program With MPI programs, the processes that execute the program all have their own local data. Typically one process will be on one core, each process can then access its own data locally and use message passing to get other data from other cores. In MPI programming the environment needs to be initialized before it can be used, and finalized when it&rsquo;s done.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://nicktehrany.github.io/notes/in4049tu-introduction-to-high-performance-computing/content/parallel-programming/"><meta property="og:image" content="https://nicktehrany.github.io"><meta property="article:section" content="notes">
<meta property="article:published_time" content="2021-09-14T15:50:41+02:00">
<meta property="article:modified_time" content="2021-09-14T15:50:41+02:00"><meta property="og:site_name" content="Nick Tehrany">
<meta property="article:published_time" content="2021-09-14 15:50:41 +0200 +0200">
</head>
<body class=dark-theme>
<div class=container>
<header class=header>
<span class=header__inner>
<a href=/ style=text-decoration:none>
<div class=logo>
<span class=logo__mark>$</span>
<span class=logo__text>cd nicktehrany</span>
<span class=logo__cursor>
</span>
</div>
</a>
<span class=header__right>
<nav class=menu>
<ul class=menu__inner><li><a href=/awards>Awards</a></li><li><a href=/publications>Publications</a></li><li><a href=/projects>Projects</a></li><li><a href=/posts>Blog</a></li><li><a href=/notes>Uni Notes</a></li>
</ul>
</nav>
<span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
</span>
<span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg>
</span>
</span>
</span>
</header>
<div class=content>
<main class=posts>
<div class=post-info>
<p>
</p>
</div>
<article>
<h1 class=post-title>
<a href=https://nicktehrany.github.io/notes/in4049tu-introduction-to-high-performance-computing/content/parallel-programming/>Parallel Programming</a>
</h1>
<div class=post-content>
<p>For distributed memory MPI is used as programming model, with shared memory OpenMP is used, and for GPUs CUDA is used.</p>
<h3 id=mpi-program>MPI Program</h3>
<p>With MPI programs, the processes that execute the program all have their own local data. Typically one process will be on one core, each process can then access its own data locally and use message passing to get other data from other cores. In MPI programming the environment needs to be initialized before it can be used, and finalized when it&rsquo;s done. <code>numberOfProcs</code> is set to the total number of processes (e.g. with 4 processes this is 4), and <code>rank</code> is the rank of the process, this starts at 0 (!!), so the first process will have rank 0, second will have rank 2, and so forth.</p>
<h3 id=point-to-point-communication>Point-to-Point Communication</h3>
<p>For enabling communication for processes that don&rsquo;t share memory.</p>
<p><code>MPI_Send</code> and <code>MPI_Recv</code> are both blocking calls, therefore deadlocks can occur and should be avoided.</p>
<p>MPI Datatypes are used to tell it how to interpret binary values from the send buffer/receive buffer, convert them etc. It has a bunch of predefined datatypes such as <code>MPI_CHAR</code> or <code>MPI_INT</code>.</p>
<p>MPI also has <code>MPI_Sendrecv</code> which sends one message and receives another in any order, and buffers (send, and recv buffers) have to different and cannot overlap. There is also the <code>MPISendrecv_replace</code> the first sends the message then receives using the same buffer.</p>
<p><code>MPI_Isend</code> and <code>MPI_Irecv</code> are the non-blocking counterparts to the prior mentioned ones. One could then also use the <code>MPI_Wait</code> to block until it&rsquo;s completed, typically this is done after some work is completed and the process needs the data from the recv.</p>
<p>Four send modes in MPI:</p>
<ul>
<li>Standard mode: Block until the message is fully transferred.</li>
<li>Synchronous mode: Block until a reply (the recv) from the receiver has arrived.</li>
<li>Buffered mode: Block until the message (to be sent) is copied to a buffer (specified by user)</li>
<li>Ready mode: If a receive exists only then does this succeed. Not recommended to be used</li>
</ul>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
</div>
</article>
<hr>
<div class=post-info>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
332 Words
</p>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
2021-09-14
</p>
</div>
<div class=pagination>
<div class=pagination__title>
<span class=pagination__title-h>Read other posts</span>
<hr>
</div>
<div class=pagination__buttons>
<span class="button previous">
<a href=https://nicktehrany.github.io/notes/in4049tu-introduction-to-high-performance-computing/content/poisson-equation/>
<span class=button__icon>←</span>
<span class=button__text>Poisson Equation</span>
</a>
</span>
<span class="button next">
<a href=https://nicktehrany.github.io/notes/in4049tu-introduction-to-high-performance-computing/content/parallel-and-distributed-architecture/>
<span class=button__text>Parallel and Distributed Architecture</span>
<span class=button__icon>→</span>
</a>
</span>
</div>
</div>
</main>
</div>
<footer class=footer>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css>
<div>
<div>
&nbsp; <a href=https://github.com/nicktehrany target=_blank rel=noopener title=Github><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a> &nbsp;&nbsp; <a href=https://www.linkedin.com/in/nicktehrany/ target=_blank rel=noopener title=Linkedin><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a> &nbsp;
<a href=https://www.semanticscholar.org/author/Tehrany/2105151990 target=_self><i class="ai ai-semantic-scholar ai-2x"></i></a>
</div>
</div>
<div class=footer__inner>
<div class=footer__content>
<span>Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>Themed by <a href=https://github.com/rhazdon/hugo-theme-hello-friend-ng>Hello Friend NG</a></span>
</div>
</div>
</footer>
</div>
<script type=text/javascript src=/bundle.min.e9f93b80e78a22e6f04cbb5f73e0f9c4ba60ff73a2a0ef85965c688f93dd1f2722a282e30e485603e4c65b1b346720e35f213435ec5556e196a97a68d097c80f.js integrity="sha512-6fk7gOeKIubwTLtfc+D5xLpg/3OioO+Fllxoj5PdHyciooLjDkhWA+TGWxs0ZyDjXyE0NexVVuGWqXpo0JfIDw=="></script>
</body>
</html>