<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>IN4331 Web-Scale Data Management on Nick Tehrany</title>
        <link>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/</link>
        <description>Recent content in IN4331 Web-Scale Data Management on Nick Tehrany</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 15 Apr 2021 08:34:56 -0600</lastBuildDate>
        <atom:link href="https://nicktehrany.github.io/notes/in4331-web-scale_data_management/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>NoSQL - Design Principles</title>
            <link>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/no_sql_design/</link>
            <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
            
            <guid>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/no_sql_design/</guid>
            <description>Replication Master-Slave Replication All updates are made directly to the master which then propagates the changes to all the slaves.
P2P Replication Replication without a master node, now updates can be on any of the replicas which then propagate the updates to all the replicas.
Distributed Transactions Two Phase Commit (2PC) Transactions are submitted to a coordinator which then sends a prepare to all workers. The workers log the request and respond to the coordinator.</description>
            <content type="html"><![CDATA[<h2 id="replication">Replication</h2>
<h3 id="master-slave-replication">Master-Slave Replication</h3>
<p>All updates are made directly to the master which then propagates the changes to all the slaves.</p>
<h3 id="p2p-replication">P2P Replication</h3>
<p>Replication without a master node, now updates can be on any of the replicas which then propagate the updates to all the replicas.</p>
<h2 id="distributed-transactions">Distributed Transactions</h2>
<h3 id="two-phase-commit-2pc">Two Phase Commit (2PC)</h3>
<p>Transactions are submitted to a coordinator which then sends a prepare to all workers. The workers log the request and respond to the coordinator. When the coordinator receives an <em>ready</em> from all the workers it sends a commit message to all workers which says that the workers should do all the work that was proposed in the prepare. In the prepare the workers just say if the request is possible. If any of the workers responds with a <em>failure</em> the coordinator will stop the request and tell all the workers to abort via an <em>ABORT</em> message and any preparation work by the worker will be stopped (clean the log).</p>
<h3 id="linearizability-vs-serializability">Linearizability vs. Serializability</h3>
<p>In linearizability there is one correct order of operations on one element that all servers have to agree upon. With serializability there can be multiple orders of operations across servers, however the final state of the database is the same with any of the orders and is consistent to the operations that were run and expected.</p>
<h3 id="base">Base</h3>
<ul>
<li><strong>B</strong>asically <strong>A</strong>vailable</li>
<li><strong>S</strong>oft State</li>
<li><strong>E</strong>ventually Consistent</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Introduction</title>
            <link>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/introduction/</link>
            <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
            
            <guid>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/introduction/</guid>
            <description>Web scale scale data management is the management of large scale datasets with the goal of how to efficiently store, query, and run large amounts of transactions on the datasets.
Multiple different systems exist, such as P2P systems or cloud storage.</description>
            <content type="html"><![CDATA[<p>Web scale scale data management is the management of large scale datasets with the goal of how to efficiently store, query, and run large amounts of transactions on the datasets.</p>
<p>Multiple different systems exist, such as P2P systems or cloud storage.</p>
]]></content>
        </item>
        
        <item>
            <title>P2P Storage</title>
            <link>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/p2p/</link>
            <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
            
            <guid>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/p2p/</guid>
            <description>Databases have some sort of model to represent the data in this model,
Relational databases Based on the relational model, it typically presented in tables that have some relation to each other among which tables can be joined, and includes indices.
Application DB The benefit of relational DBs is that they can easily be incorporated into multiple applications since they have defined schemas for the tables and a universal interface. Each application has its own data model and applications then communicate via some sort of messaging model.</description>
            <content type="html"><![CDATA[<p>Databases have some sort of model to represent the data in this model,</p>
<h2 id="relational-databases">Relational databases</h2>
<p>Based on the relational model, it typically presented in tables that have some relation to each other among which tables can be joined, and includes indices.</p>
<h3 id="application-db">Application DB</h3>
<p>The benefit of relational DBs is that they can easily be incorporated into multiple applications since they have defined schemas for the tables and a universal interface. Each application has its own data model and applications then communicate via some sort of messaging model. However now since each application has its own data model there is no unique model for all databases (no central data model as there wold be with integration DBs that integrate multiple applications into a single central database).</p>
<p>These types of databases are also easier to manage since there is no one central point where all data needs to go and there is no need for synchronization between the different points accessing the central point (easier to scale, distribute, and load balance).</p>
<h2 id="p2p-storage">P2P Storage</h2>
<p>The goal with P2P systems is to scale out (distribute the data) that also have resilience to failures, such that failing nodes can easily be handled (and replaced).</p>
<p>There are several different P2P systems:</p>
<ul>
<li>
<p><strong>Client-Server</strong>: A central server that provides some service or content and clients directly connect to the central server.</p>
</li>
<li>
<p><strong>Centralized P2P</strong>: A central entity to provide a service that is used for indexing of data/groups of where data is located on other peers, and peers are connected to each other. They can request a location of some data from the central server and receive where the data is located and can request the data from that node. This poses a difficulty of load balancing of hot and cold data (what is hot? when is it how? how often replicate it?), and the system still relied on a central server for indexing.</p>
</li>
<li>
<p><strong>Pure P2P</strong>: All nodes are connected to each other and there is no single entity. This allows for leaving and joining to the system without any loss, however it is difficult to manage indexing and what data is on what node, since each node would need to broadcast the data it has to all other nodes to let them know that they have this data.</p>
</li>
<li>
<p><strong>Hybrid P2P</strong>: This aims to solve the problem of pure P2P by having super peers to which individual peers are connected and super peers are connected to each other. This allows for dynamic central entities that host indexing.</p>
</li>
<li>
<p><strong>Pure P2P (DHT Based)</strong>: Distributed hash tables (DHT) where searching and routing (and having information about other machines) can all be done in $\mathcal{O}(\log{}n)$. Can only be hashed by a single value, so if for example you want to share songs you need multiple DHTs to allow for hashing only by song, by song with artist, and so forth, so that songs can be found without all the information (valid existing hashes can be created without all the info). DHTs have a ring structure (which is where the $\log{}n$ comes from). Solving load balancing can be done by hashing yourself when joining, then have a resulting hash range and have yourself routed along the network to the range where you ended up in (this works since the hash function is uniformly distributed and have the avalanche effect). Finding a hash is done by each node maintaining information of $\log{}n$ other nodes in a <em>finger table</em> where different distances to on the ring are stored and which nodes are responsible for that. The addresses you need are</p>
<p>$$targedId = (currId + 2^i) \text{ mod } 2^m$$</p>
<p>Routing requests for a node can then be directly forwarded to the node by sending it to the most distant known node which is below the value that is being looked up (always cutting the search space in half).</p>
</li>
</ul>
<h3 id="amazon-dynamo">Amazon Dynamo</h3>
<p>Assumes that there are not malicious nodes (no need for fraud detection), and implements a <code>put()</code> and <code>get()</code> for the storage system based on a DHT. In order to answer queries fast, each node maintains a full finger table (therefore the ring is fully connected) and there are no varying response times in the network. For load balancing each node also creates an additional virtual server so that if a node if under heavy load the virtual server (its partitions it is responsible for) can just be moved to a new node.</p>
<p>Updates (after <code>put()</code>) updates are propagated asynchronously, resulting in eventual consistency. It also uses read/write quorums such that the <code>put()</code> operation does not return until the majority of replicas have been updated (or however many nodes the quorum requires).</p>
]]></content>
        </item>
        
        <item>
            <title>Info</title>
            <link>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/info/</link>
            <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
            
            <guid>https://nicktehrany.github.io/notes/in4331-web-scale_data_management/info/</guid>
            <description>IN4331 Web-Scale Data Management notes at TUDelft (Q4).
Studyguide: https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=55287
The content is based on the lecture material/slides and summarized by myself.</description>
            <content type="html"><![CDATA[<p>IN4331 Web-Scale Data Management notes at TUDelft (Q4).</p>
<p>Studyguide: <a href="https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=55287">https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=55287</a></p>
<p>The content is based on the lecture material/slides and summarized by myself.</p>
]]></content>
        </item>
        
    </channel>
</rss>
