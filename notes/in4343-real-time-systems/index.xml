<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>IN4343 Real Time Systems on Nick Tehrany</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/</link><description>Recent content in IN4343 Real Time Systems on Nick Tehrany</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 08 Feb 2022 10:21:30 +0100</lastBuildDate><atom:link href="https://nicktehrany.github.io/notes/in4343-real-time-systems/index.xml" rel="self" type="application/rss+xml"/><item><title>Scheduling Aperiodic Tasks</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-aperiodic-tasks/</link><pubDate>Sat, 19 Feb 2022 14:33:05 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-aperiodic-tasks/</guid><description>Earliest Due Date (EDD) With this algorithm, we select the task with the earliest relative deadline to run first. However, the system assumes that all tasks arrive simultaneously, hence it knows all deadlines, and preemption is not used. The resulting performance is to minimize the maximum lateness.
Optimality ]
]
Based on this, if we continue swapping, we end up with the plan that minimizes that maximum lateness. Overall, EDD takes $O(n\text{log}n)$ for queue ordering.</description><content type="html"><![CDATA[<h2 id="earliest-due-date-edd">Earliest Due Date (EDD)</h2>
<p>With this algorithm, we select the task with the earliest <strong>relative</strong> deadline to run first. However, the system assumes that all tasks arrive simultaneously, hence it knows all deadlines, and preemption is not used. The resulting performance is to minimize the maximum lateness.</p>
<h3 id="optimality">Optimality</h3>
<p><img src="/images/IN4343/edd-optimality-1.png" alt="EDD Optimality 1">]</p>
<p><img src="/images/IN4343/edd-optimality-2.png" alt="EDD Optimality 2">]</p>
<p>Based on this, if we continue swapping, we end up with the plan that minimizes that maximum lateness. Overall, EDD takes $O(n\text{log}n)$ for queue ordering.</p>
<h2 id="earliest-deadline-first-edf">Earliest Deadline First (EDF)</h2>
<p>With this algorithm we use the earliest absolute deadline. Now the tasks can arrive at any time, and we use preemption (assuming no overheads for switching). It again minimizes the maximum lateness. So the schedule checks each time a new task arrives, if it should be scheduled.</p>
<p>Optimality is shown by turning a feasible schedule to an EDF schedule. For this we essentially just iterate through the tasks and check if that has the earliest deadline, if not we swap it with the task that has the earliest deadline.</p>
<p><img src="/images/IN4343/edf_optimality.png" alt="EDF Optimality"></p>
<p>EDF requires $O(n)$ to insert a task in the queue.</p>
<h2 id="non-preemptive-scheduling">Non-Preemptive Scheduling</h2>
<p>It becomes more difficult now if we cannot preempt tasks, but tasks arrive asynchronously. This is because if one task runs a longer time, and another with a short deadline arrives, the long running cannot be interrupted to have the other run, possibly causing the shorter one to miss its deadline.</p>
<p>Given the construction of all possible schedules in a tree, the complexity for finding a feasible solution is $O(nn!)$ with $n!$ leaves and $n$ depth of the tree.</p>
<p>To improve it we can prune the tree if a feasible schedule is found or the addition of a node to the current schedule causes deadline misses. However, this still leads to bad worst case time complexity.</p>
<p>Therefore, we can use a heuristical approach. This selects the step to take at any level by minimizing an optimization function (custom function that can put different weight on variables, e.g. constraints, and minimizes the resulting value). If the leaf contains a infeasible schedule, we go back one level and go to the second best option.</p>
<p><img src="/images/IN4343/np-schedule-optimization.png" alt="Non-Preemptive Scheduling Optimization"></p>
<p>precedence constraints are then handled by assigning the appropriate weights to the heuristical function.</p>
]]></content></item><item><title>Modeling Part 2</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-2/</link><pubDate>Tue, 15 Feb 2022 16:29:20 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-2/</guid><description>Scheduling Problem Given a set of tasks, a set of processors, a set of resources, and a performance objective, the goal is to find assignments for the processors and resources to the tasks such that it results in a maximum-value schedule under the constraints.
Common definitions used are $\sigma$ for the schedule and $\Gamma$ for the tasks, and $A$ for the algorithm that generates the schedule.
The scheduling problem is shown to be NP-Hard (non-deterministic polynomial), meaning that finding a feasible schedule grows exponentially with the number of tasks for the schedule.</description><content type="html"><![CDATA[<h2 id="scheduling-problem">Scheduling Problem</h2>
<p>Given a set of tasks, a set of processors, a set of resources, and a performance objective, the goal is to find assignments for the processors and resources to the tasks such that it results in a <strong>maximum-value</strong> schedule under the constraints.</p>
<p>Common definitions used are $\sigma$ for the schedule and $\Gamma$ for the tasks, and $A$ for the algorithm that generates the schedule.</p>
<p>The scheduling problem is shown to be NP-Hard (non-deterministic polynomial), meaning that finding a feasible schedule grows exponentially with the number of tasks for the schedule.</p>
<h2 id="computational-complexity">Computational Complexity</h2>
<p>We are mainly interested in the execution time that the algorithm needs to finish, including doing the computations. Therefore, we take the worst case execution time of a larger problem (since these show worst case much better than small problems) and compare using the Big-O notation. Then an algorithm is in <strong>polynomial time</strong> if it has a time complexity of the number of tasks to some exponent, specifically $T(n)=O(n^a), a&gt;1$.</p>
<h2 id="taxonomy-of-algorithms">Taxonomy of Algorithms</h2>
<h3 id="preemptive-vs-non-preemptive">Preemptive vs. Non-Preemptive</h3>
<p>These are based on if the tasks can be interrupted (and restored or restarted afterwards).</p>
<h3 id="static-vs-dynamic">Static vs. Dynamic</h3>
<p>Static scheduling is based on fixed parameters that are assigned to the tasks prior to the creation of a task. Dynamic on the other hand is where these parameters might change at runtime.</p>
<h3 id="online-vs-offline">Online vs. Offline</h3>
<p>With online scheduling the schedule is created in the beginning or at the arrival of a new task. Offline scheduling uses a pre-determined table driven schedule, which we can only run if we know what tasks will arrive in the future.</p>
<h3 id="optimal-vs-heuristic">Optimal vs. Heuristic</h3>
<p>Optimal maximizes the value of the performance criteria. Heuristic uses a heuristical approach to maximize, however this will not be optimal.</p>
<h3 id="admission-control">Admission Control</h3>
<p>This tells a task whether it is accepted or rejected. This is necessary to avoid the domino effect of failed jobs. For instance, we have a job that is running, it gets interrupted by a higher priority one, this happens again a couple of times until we have one job that finishes before its deadline. Then continuing the interrupted jobs (in order of highest priority to lowest) will often mean that each of them will finish after their deadline.</p>
<p><img src="/images/IN4343/admission_control.png" alt="Admission Control"></p>
<h2 id="optimal-criteria">Optimal Criteria</h2>
<p>Upon what criteria do we optimize? We need to ensure the schedule is feasible (if there is one), minimize the maximum lateness or deadline misses, maximize the cumulative value of the tasks run, and include the cost for consuming resources.</p>
<p><img src="/images/IN4343/optimal_criteria.png" alt="Optimal Criteria"></p>
<h2 id="grahams-notation">Graham&rsquo;s Notation</h2>
<p>This notation is used to systematically describe the problem and algorithm.</p>
<p><img src="/images/IN4343/graham_notion.png" alt="Graham&rsquo;s Notion"></p>
]]></content></item><item><title>Modeling Part 1</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-1/</link><pubDate>Fri, 11 Feb 2022 14:01:01 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-1/</guid><description>The goal of modeling is to
abstract away the system components (hardware and software) establish assumptions, parameters for model description, variables to use, and understand the constraints on the system define the metrics upon which to optimize the system (performance/cost) Tasks A task is defined as a sequence of instructions (e.g. the code to execute) which is run by the processor until it&amp;rsquo;s finished. We then have the activation time that depicts the time the task is created, the start time for the time the task starts running, the computation time, and the finishing time.</description><content type="html"><![CDATA[<p>The goal of modeling is to</p>
<ul>
<li>abstract away the system components (hardware and software)</li>
<li>establish assumptions, parameters for model description, variables to use, and understand the constraints on the system</li>
<li>define the metrics upon which to optimize the system (performance/cost)</li>
</ul>
<h2 id="tasks">Tasks</h2>
<p>A task is defined as a sequence of instructions (e.g. the code to execute) which is run by the processor until it&rsquo;s finished. We then have the <strong>activation time</strong> that depicts the time the task is created, the <strong>start time</strong> for the time the task starts running, the <strong>computation time</strong>, and the <strong>finishing time</strong>.</p>
<p>Additionally, the <strong>execution time</strong> is given as $f_i - s_i$ with finishing time $f_i$ and start time $s_i$ for the specific task. <strong>response time</strong> is given as $f_i-a_i$ with $a_i$ arrival time for the task.</p>
<h2 id="ready-queue">Ready Queue</h2>
<p>In concurrent systems there can be several tasks that are in the active state, but only one is actually being executed at any point in time. Therefore, such active tasks that are not currently running are in the <strong>ready</strong> state. We then also have a <strong>ready queue</strong> in which the tasks in a ready state are being queued. The scheduling policy then decides how to dispatch the tasks from the ready queue (e.g. FIFO, priority based, LIFO, etc.).</p>
<p>If the system supports <strong>preemption</strong> tasks can be interrupted when another tasks with higher priority needs to be run (e.g. store task states, run higher priority one, restore prior task states once high priority one is done). However, this means that the task is placed again into the ready queue.</p>
<h2 id="task-states">Task States</h2>
<p>Tasks can be in the <strong>idle state</strong> or a <strong>blocked state</strong> as well, where in the idle state they do not do any work and rather are waiting for the next period, and in the blocked state they are waiting for a signal (e.g. with shared memory wait to receive signal that it&rsquo;s safe to access the memory).</p>
<h2 id="definitions">Definitions</h2>
<p><img src="/images/IN4343/deadline.png" alt="Definition"></p>
<p>A RT task is then called <strong>feasible</strong> when it completes before the absolute deadline $f_i \leq d_i$ or $R-I \leq D_i$. <strong>Schedulable</strong> then means that there exists an algorithm that can produce a feasible schedule.</p>
<p>We have additional timing constraints <img src="/images/IN4343/timing_constraints.png" alt="Timing Constraints">. Also worth mentioning is that jobs are task instances. A task specifies something to do and a job is then an instance of doing that task, meaning multiple jobs of a task can exist.</p>
<h3 id="types-of-tasks">Types of Tasks</h3>
<ul>
<li><strong>Periodic Tasks</strong> These tasks are instantiated automatically every given time frame (their period). We can further classify <strong>single rate</strong> when tasks in the system all have the exact same period, and <strong>multi-rate</strong> where tasks have different periods.</li>
<li><strong>Aperiodic Tasks</strong> These tasks are the opposite and happen at no given time interval but rather depending on things such as external events or interrupts. Aperiodic tasks can be further classified into <strong>unbounded arrival time</strong> or <strong>event based</strong> triggering of tasks and <strong>sporadic tasks</strong> for which there is a minimum gap between arrivals (we don&rsquo;t know the exact arrival rate but at at least 8seconds elapse before any new task can arrive).</li>
</ul>
<h3 id="periodic-tasks">Periodic Tasks</h3>
<p>For periodic tasks we can then calculate the utilization as, with $C_i$ computation time and $T_i$ the task period</p>
<p>$$U_i=\frac{C_i}{T_i}$$</p>
<p>$\phi$ depicts the phase of the instance (its release time).</p>
<p><img src="/images/IN4343/phase.png" alt="phase"></p>
<h3 id="computation-time">Computation Time</h3>
<p>We can estimate the computation time using experiments of prior runs and taking their runtimes, however this fails to account for all real world scenarios, therefore we have several different execution time estimations,</p>
<p><img src="/images/IN4343/computation_time.png" alt="Computation Time"></p>
<p>Setting the safety margin factors in on the predictability (are we guaranteed to fall into the margin if it is large enough) and efficiency (if the margin is too large we are wasting resources).</p>
<h3 id="jitter">Jitter</h3>
<p>The jitter measures the variation in time for a periodic event, given as</p>
<p><img src="/images/IN4343/jitter.png" alt="Jitter"></p>
<h3 id="timing-constraints">Timing Constraints</h3>
<p>The timing constraints give bounds on the timings within the systems (e.g. minimum completion time, maximum allowed jitter, etc.). Often implicit timing constraints need to be met in order for the system to function correctly, whereas explicit timing constraints are specified for the system.</p>
<h4 id="minimum-sampling-period">Minimum Sampling Period</h4>
<p>Guarantees that the system is not overloaded using, where $U_{other}$ depicts the sum over all other tasks $\sum_{i \ne s}^{i} \frac{C_i}{T_i}$</p>
<p><img src="/images/IN4343/msp.png" alt="Minimum Sampling Period"></p>
<h3 id="maximum-sampling-period">Maximum Sampling Period</h3>
<p>Applies the same logic but rather uses the worst-case timings.</p>
<h3 id="precedence-constraints">Precedence Constraints</h3>
<p>Often tasks need to run only after some other task has completed (they require that this other task has run prior to them running), giving us some precedence constraints on the tasks, which is represented using a directed acyclic graph. The graph represents immediate predecessors (need to run just before the task, e.g. task 3 can only run after task 2) and predecessors (need to run before but not directly before, e.g. task 1 needs to run before task 2 and task 2 needs to run before task 3, hence task 1 is predecessor to task 3).</p>
<p>Such graphs can then also represent <strong>fork nodes</strong> points at which multiple tasks can start once a single task has completed and <strong>join nodes</strong> which are tasks that require multiple tasks having completed. We also have <strong>switch nodes</strong> that based on a decision have multiple tasks run (but not all their child nodes) and similarly <strong>if-then nodes</strong> that have the same but just two child nodes of which one runs.</p>
]]></content></item><item><title>Introduction</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/introduction/</link><pubDate>Tue, 08 Feb 2022 10:22:07 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/introduction/</guid><description>What is a Real-Time system? Real-Time systems are the systems that depend on their output (e.g. decisions from computations) and on the time in which these were produced. For example, airplanes will have many smaller systems that produce some result that is required to happen within some time frame (e.g. getting the airplane speed every couple of seconds). Therefore, the computations in Real-Time systems must be performed within a certain timing constraint.</description><content type="html"><![CDATA[<h2 id="what-is-a-real-time-system">What is a Real-Time system?</h2>
<p>Real-Time systems are the systems that depend on their output (e.g. decisions from computations) and on the time in which these were produced. For example, airplanes will have many smaller systems that produce some result that is required to happen within some time frame (e.g. getting the airplane speed every couple of seconds). Therefore, the computations in Real-Time systems must be performed within a certain <strong>timing constraint</strong>. Additionally, the system has to provide <em>bounded response times</em> for the computation under all possible scenarios, such that response times can be predicted for any possible input.</p>
<p>For real-time systems, often the computations are related to its environment (like the airplane example), and operations are adapted to this environment.</p>
<h2 id="classes-of-real-time-tasks">Classes of Real-Time Tasks</h2>
<ul>
<li><strong>Hard</strong> Real Time: the system has to generate a response before the deadline (e.g. safety critical systems).</li>
<li><strong>Soft</strong> Real Time: the system does not have to meet the deadline all the time, some misses are fine (e.g. keyboard I/O can sometimes lag).</li>
<li><strong>Firm</strong> Real Time: similar to Soft real time but now there is no benefit for completing computations after the deadline, results are useless after that point.</li>
</ul>
<h2 id="properties--requirements-of-real-time-systems">Properties &amp; Requirements of Real-Time Systems</h2>
<ul>
<li>Often resources are limited, therefore high efficiency in resource management is required.</li>
<li>If resources are shared, there has to be some temporal isolation to avoid tasks interfering.</li>
<li>As these systems often interact with the environment, they have to have predictable results and required time to produce these.</li>
<li>Tasks can also be very different, therefore the system has to be able to adapt and handle these, as well as being able to handle overloads at times.</li>
</ul>
<h2 id="classes-of-control-systems">Classes of Control Systems</h2>
<p>With real-time systems, as stated before, there is most commonly an object being controller. This object is then called the controlled object (the system), where the real-time system is the controller (doing the computations for changes), and the operator is the environment.</p>
<h3 id="open-loop-control-system">Open-Loop Control System</h3>
<p>In these systems the feedback from the actions are loosely dependent on the environment and there is no feedback from the controlled object to the environment.</p>
<h3 id="closed-loop-control-system">Closed-Loop Control System</h3>
<p>In these, there exists frequent interaction between the system and the environment. Therefore, feedback is going from the environment to the system and from the system to the controller. This often happens at a sampling rate, depending on the use case.</p>
<h3 id="multi-level-feedback-system">Multi-Level Feedback System</h3>
<p>Here feedback is generated for different systems, of the larger system, at different rates. For example in the airplane, the airspeed may be collected every couple of seconds, and the altitude as well, but the autopilot checks all these and others every half a second.</p>
<h2 id="taxonomy-of-real-time-systems">Taxonomy of Real-Time Systems</h2>
<p><strong>Static</strong> analysis can be done at compile time, this implies that duration of tasks is know, and therefore we can tell what the Worst Case Execution Time (WCET) is. However, this is only possible for static systems, and very simple dynamic systems.</p>
<p>We can then also have systems that have a know task duration (either single or multiple durations but all known) which implies that it is a <strong>periodic</strong> system. On the contrary, if we do not know this, it is called an <strong>aperiodic</strong> or sporadic system. These create dynamic situations (e.g. autonomous cars).</p>
]]></content></item><item><title>Info</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/info/</link><pubDate>Tue, 08 Feb 2022 10:21:30 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/info/</guid><description>IN4343 Real Time Systems: Studyguide: https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;amp;_NotifyTextSearch_
Book: Hard Real-Time COmputing Systems: Predictable Scheduling Algorithms and Applications Third Edition
All content and images are based on and retrieved from the lecture slides and/or the previously mentioned book and/or any other content that is provided in the course.
Authors Nick Tehrany</description><content type="html"><![CDATA[<h2 id="in4343-real-time-systems">IN4343 Real Time Systems:</h2>
<p>Studyguide: <a href="https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;_NotifyTextSearch_">https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;_NotifyTextSearch_</a></p>
<p>Book: Hard Real-Time COmputing Systems: Predictable Scheduling Algorithms and Applications Third Edition</p>
<p>All content and images are based on and retrieved from the lecture slides and/or the previously mentioned book and/or any
other content that is provided in the course.</p>
<h3 id="authors">Authors</h3>
<ul>
<li><a href="https://github.com/nicktehrany">Nick Tehrany</a></li>
</ul>
]]></content></item></channel></rss>