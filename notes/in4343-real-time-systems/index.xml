<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>IN4343 Real Time Systems on Nick Tehrany</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/</link><description>Recent content in IN4343 Real Time Systems on Nick Tehrany</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 08 Feb 2022 10:21:30 +0100</lastBuildDate><atom:link href="https://nicktehrany.github.io/notes/in4343-real-time-systems/index.xml" rel="self" type="application/rss+xml"/><item><title>Non-Preemptive Scheduling</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/non-preemptive-scheduling/</link><pubDate>Tue, 05 Apr 2022 19:43:19 +0200</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/non-preemptive-scheduling/</guid><description>While preemption allows to scheduler urgent tasks quicker, since we do not have to wait for other tasks to finish but rather directly scheduler the urgent task, it also has the disadvantage of added overhead for context switching. This added overhead can also cause more preemption, since we increase the execution time with the additional time required for context switching, and this can cause more preemptions to happen during that prolonged time.</description><content type="html"><![CDATA[<p>While preemption allows to scheduler urgent tasks quicker, since we do not have to wait for other tasks to finish but rather directly scheduler the urgent task, it also has the disadvantage of added overhead for context switching. This added overhead can also cause more preemption, since we increase the execution time with the additional time required for context switching, and this can cause more preemptions to happen during that prolonged time. We also use cache locality, since it&rsquo;s replaced with the new task and again when the task is preempted, these are called cache-related preemption delays (CRPD). Therefore, with preemption we have less predictable WCET (worst case execution time) due to all the overheads.</p>
<p>Without preemption we could also have the disadvantage that it could reduce the schedulability due to blocking.</p>
<h2 id="hybrid-np-schemes">Hybrid NP Schemes</h2>
<h3 id="preemption-threshold">Preemption Threshold</h3>
<p>With this only tasks with a very high priority can preempt tasks with a low priority, by defining a minimum priority threshold for every task stating the tasks it can preempt.</p>
<h3 id="deferred-preemption">Deferred Preemption</h3>
<p>We define for each task the longest time period during its execution that it cannot preempted.</p>
<h3 id="task-splitting-or-fixed-preemption-points">Task Splitting (or Fixed Preemption Points)</h3>
<p>We split the tasks into non-preemptable code chunks, which preemption can then only happen in specific code sections.</p>
]]></content></item><item><title>Jitter</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/jitter/</link><pubDate>Mon, 04 Apr 2022 16:33:40 +0200</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/jitter/</guid><description>Jitter Analysis This is typically done for multi-processor systems but can also be used for single processor ones. Defines the Finalization Jitter ($FJ$) as the variation in finalization times, and the Activation Jitter ($AJ$) as the variation in activation times. The goal of jitter analysis is then to determine the schedulability in the context of jitter and with it be able to determine response times. We then look at the worst case response time and the best case response time, which depict the response time that tasks should fall in between, and not outside of.</description><content type="html"><![CDATA[<h2 id="jitter-analysis">Jitter Analysis</h2>
<p>This is typically done for multi-processor systems but can also be used for single processor ones. Defines the <strong>Finalization Jitter ($FJ$)</strong> as the variation in finalization times, and the <strong>Activation Jitter ($AJ$)</strong> as the variation in activation times. The goal of jitter analysis is then to determine the schedulability in the context of jitter and with it be able to determine response times. We then look at the worst case response time and the best case response time, which depict the response time that tasks should fall in between, and not outside of.</p>
<p>An (a task can have multiple) <strong>Optimal Instant</strong> of a task assumes its best case response time and appears when the lowest amount of preemption by higher priority tasks appears.</p>
]]></content></item><item><title>Dynamic Servers</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/dynamic-servers/</link><pubDate>Sun, 03 Apr 2022 18:36:29 +0200</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/dynamic-servers/</guid><description>Total Bandwidth Server (TBS) It is designed to be used with EDF, where each aperiodic request is assigned a deadline and aperiodic jobs are inserted into the ready queue which is then served with EDF. Periodic tasks are directly going into the ready queue. Deadlines are assigned based on calculation with the computation time of the aperiodic job, and find the minimal period we can assign to the job (also account for the maximum possible utilization of the server).</description><content type="html"><![CDATA[<h2 id="total-bandwidth-server-tbs">Total Bandwidth Server (TBS)</h2>
<p>It is designed to be used with EDF, where each aperiodic request is assigned a deadline and aperiodic jobs are inserted into the ready queue which is then served with EDF. Periodic tasks are directly going into the ready queue. Deadlines are assigned based on calculation with the computation time of the aperiodic job, and find the minimal period we can assign to the job (also account for the maximum possible utilization of the server).</p>
<p><img src="/images/IN4343/tbs_deadline.png" alt="Total Bandwidth Server Deadline Assignment"></p>
<h2 id="constant-bandwidth-server-cbs">Constant Bandwidth Server (CBS)</h2>
<p>It works similar to TBS by assigning for assigning of deadlines, but also keeps track of the execution for jobs with a budget, such that they cannot overrun their computation time. On overruns we postpone the deadline and reapply EDF.</p>
]]></content></item><item><title>Fixed Priority Servers</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/fixed-priority-servers/</link><pubDate>Sun, 03 Apr 2022 16:50:10 +0200</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/fixed-priority-servers/</guid><description>Hybrid Task Sets These task sets contain both periodic and aperiodic tasks, for example aperiodic tasks arising from exceptions or interrupts. The periodic tasks often have hard deadlines, compared to the aperiodic ones with soft deadlines.
The goals of scheduling in such a system are to:
Minimize the response times for the aperiodic tasks, requiring to process them as soon as they arrive. Period tasks should be executed before their deadline such that they do not miss deadlines because of the aperiodic tasks.</description><content type="html"><![CDATA[<h2 id="hybrid-task-sets">Hybrid Task Sets</h2>
<p>These task sets contain both periodic and aperiodic tasks, for example aperiodic tasks arising from exceptions or interrupts. The periodic tasks often have hard deadlines, compared to the aperiodic ones with soft deadlines.</p>
<p>The goals of scheduling in such a system are to:</p>
<ol>
<li>Minimize the response times for the aperiodic tasks, requiring to process them as soon as they arrive.</li>
<li>Period tasks should be executed before their deadline such that they do not miss deadlines because of the aperiodic tasks.</li>
</ol>
<h3 id="opportunistic-scheduling">Opportunistic Scheduling</h3>
<p>Often also referred to as background scheduling, we execute the aperiodic job when the CPU is idle from running periodic tasks.</p>
<p>This gives good performance for periodic tasks, but response time for aperiodic jobs is bad.</p>
<p>On the other hand prioritizing the aperiodic job could easily cause the periodic task to miss its deadline, also making it an undesirable scheduling approach for hybrid task sets.</p>
<h2 id="server-concept">Server Concept</h2>
<p>A server is responsible for controlling the execution of aperiodic tasks, it itself is a process that is run as a periodic task that when active schedules the ready aperiodic tasks. For this it uses a <em>service queue</em> of aperiodic tasks, from which it gets tasks and places them in the <em>ready queue</em> whenever it runs. In addition the periodic tasks are going directly into the ready queue.</p>
<p>For all the servers, we assume that scheduling is using RM for the periodic tasks.</p>
<h3 id="polling-server">Polling Server</h3>
<p>Given a period $T_S$ and a computation budget $C_S$ the server at the beginning of each period initializes the budget and over the time of the period consumes this budget as aperiodic tasks are executed. The execution of jobs will end when the budget reaches 0. When no aperiodic tasks are there, the budget is set to 0 and the token returns to the periodic tasks.</p>
<p><img src="/images/IN4343/PS_schedulability.png" alt="Polling Server Schedulability"></p>
<p>In order to find the parameters of the polling server (computation time and period) we can find the bounds that still ensure feasibility.</p>
<p><img src="/images/IN4343/ps_dimensioning.png" alt="Polling Server Dimensioning"></p>
<h3 id="deferrable-server">Deferrable Server</h3>
<p>This server is the same as the polling server, but if there are no pending jobs the budget is not set to 0 (it stays). This means that when an aperiodic task arrives, it can start immediately, hence there are lower delays with them. While this helps with the response times of the aperiodic tasks, it can produce deadline misses for the periodic tasks. This is due to the possibility that computation is deferred, which means treating it as a periodic task is not valid (therefore it does not actually violate the feasibility of RM since it is using RM and can violate schedulability with deadline misses).</p>
<h2 id="slack-stealer">Slack Stealer</h2>
<p>This approach uses a passive task that attempts to create a time budget for aperiodic tasks by taking time from periodic tasks. As there is no benefit to finish a periodic task before its deadline, we can steal the free time for it and push it as far as possible to finish.</p>
]]></content></item><item><title>Scheduling Periodic Tasks</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-periodic-tasks/</link><pubDate>Tue, 22 Feb 2022 13:49:26 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-periodic-tasks/</guid><description>Concepts Again, tasks are defined with $\Gamma={T_1,T_2,&amp;hellip;,T_n}$ and each task has a $C_I$ worst-case computation time, $T_i$ activation period, $D_i$ relative deadline, and $\Phi_i$ initial arrival time (phase).
Hyperperiod This depicts the minimum time period after which the schedule repeats. Therefore, it is the least common multiple of the periods of all the tasks.
Schedulability Feasibility is defined similar to aperiodic tasks, however each task is required to be able to be executed for its defined $C_i$ time in every interval $[a_{ik},d_{ik}],k=1,2,&amp;hellip;$.</description><content type="html"><![CDATA[<h2 id="concepts">Concepts</h2>
<p>Again, tasks are defined with $\Gamma={T_1,T_2,&hellip;,T_n}$ and each task has a $C_I$ worst-case computation time, $T_i$ activation period, $D_i$ relative deadline, and $\Phi_i$ initial arrival time (phase).</p>
<h3 id="hyperperiod">Hyperperiod</h3>
<p>This depicts the minimum time period after which the schedule repeats. Therefore, it is the least common multiple of the periods of all the tasks.</p>
<h3 id="schedulability">Schedulability</h3>
<p>Feasibility is defined similar to aperiodic tasks, however each task is required to be able to be executed for its defined $C_i$ time in every interval $[a_{ik},d_{ik}],k=1,2,&hellip;$.</p>
<p>Then we can have schedulability tests that check if a scheduling policy is schedulable for the given tasks and constraints. However, some of these tests are required to show that it is <strong>certainly</strong> not schedulable, or other tests that show that it <strong>certainly</strong> is schedulable. Hence, some of these tests are exact and give a direct answer to if it is schedulable or not, however not all tests necessarily are.</p>
<p>For example, when testing if it is schedulabe for a single hyperperiod, is that enough to state that it is always schedulable?</p>
<h3 id="processor-utilization">Processor Utilization</h3>
<p>It is given as the fraction of processor time that is spent on a task,</p>
<p>$$U_i=\frac{C_i}{T_i}$$</p>
<p>Then the processor utilization is the sum over all task utilization.</p>
<p><img src="/images/IN4343/processor_utilization.png" alt="Processor Utilization"></p>
<h2 id="proportional-share-algorithm">Proportional Share Algorithm</h2>
<p>With this algorithm time slots are of length that is the greatest common divisor (GCD) of all the tasks. Then each slot for a task is proportional to its utilization, meaning time slots are the utilization of the task ($\frac{C_I}{T_i}$) for the task multiplied by the calculated GCD. With $\delta$ being the GCD, we have time slot time being</p>
<p>$$\delta_i=U_i * \Delta$$</p>
<p>Then an algorithm is feasible if</p>
<p>$$\sum_i \delta_i \leq \Delta \text{ or } \sum_i U_i \leq 1$$</p>
<p>A drawback of this algorithm is that if $\Delta$ is small, there is a lot of context switching, hence possibly a lot of overheads introduced.</p>
<h2 id="work-and-sleep-algorithm">Work-and-Sleep Algorithm</h2>
<p>Here a task is running for $C_i$ units and suspends for $T_i - C_i$ units if another task with higher priority needs  to be executed. This is very easy to implement, however, its drawback is that it can starve low priority tasks.</p>
<h2 id="timeline-cyclic-scheduling">Timeline (Cyclic) Scheduling</h2>
<p>The total time is divided into equal length slots, where we define a small cycle $\delta$ equal to he GCD, and a large cycle $T$ equal to the LCM (largest common multiple). Tasks are then placed into this smaller and larger periods, since we define the smallest period $\delta$ in which the most frequent task always needs to appear once, and apply the same for larger cycles. The schedule is then feasible if the sum of the computation times of the necessary tasks is less than or equal to $\delta$ (we only car about the required conditions, e.g. if task $A$ and $C$ never happen in a minor cycle together, we don&rsquo;t care if their sum is less than $\delta$).</p>
<p>Advantages are that it is easy to implement and schedules can be hard coded in the main loop, meaning tasks will have consistently low jitter. However, it cannot handle overloading and is sensitive to application changes.</p>
<h2 id="priority-scheduling">Priority Scheduling</h2>
<p>We assign priorities to the tasks based on their timing constraints (their deadline). There are different ways of assigning priority to a task given as,</p>
<ul>
<li><strong>Rate Monotonic (RM)</strong>: $P_i \frac{1}{T_i}$ for task $i$ and $T_i$ the period of the task. Hence, it is inversely proportional to the period, the larger the period, the lower its priority is.</li>
<li><strong>Deadline Monotonic (DM):</strong> $P_i \frac{1}{D_i}$ for task $i$ and $D_i$ the relative deadline of the task.</li>
<li><strong>Earliest Deadline First (EDF):</strong> $P_i \frac{1}{d_{ik}$ for task $i$ and $d_{ik}$ the absolute deadline of the task.</li>
</ul>
<h3 id="critical-instant">Critical Instant</h3>
<p>The critical instant of a task is the arrival time that induces the largest response time. It is essentially the worst case scenario when the task arrives concurrently with all higher priority tasks. If all tasks are schedulable in their critical instant, then the schedule is feasible.</p>
<h2 id="least-upper-bound-lub">Least Upper Bound (LUB)</h2>
<p>Given all possible task sets if we modify the computation times of the task, we find the upper bound of a task set (utilization that cannot get any higher, and which can be lower than 1 but never above 1), then one of these utilizations will give us a lower bound (lowers possible utilization). Then given a task set that has a utilization below this LUB we know that it is schedulable.</p>
<h3 id="rm-algorithm">RM Algorithm</h3>
<p>Since we don&rsquo;t want to do the calculation for finding the LUB for all scheduling algorithms and all possible task combinations, we have an algorithm to analytically quantify the LUB. Given any task set, for scheduling the LUB with RM</p>
<p>$$U_{lub}^{RM}=n(2^{\frac{1}{n}}-1), n\rightarrow \infty \implies \text{ln}2=0.69$$</p>
<h3 id="rm-test-with-hypberbolic-bound-hb">RM Test with Hypberbolic Bound (HB)</h3>
<p>It says that given a task set $\Gamma$ of $n$ periodic tasks, and each task has processor utilization $\tau_i$ it is schedulable with RM if</p>
<p>$$\prod_{i=1}^{n}(U_i+1)\leq 2$$</p>
<h3 id="comparison">Comparison</h3>
<p>HB gives a tighter bound than LL.</p>
<p><img src="/images/IN4343/RM.png" alt="LL compared to HB"></p>
<h2 id="deadline-monotonic-dm">Deadline Monotonic (DM)</h2>
<p>Unlike the Rate Monotonic, where the relative deadline is the same as the period, now the relative deadline is before the end of the period. Similarly, with RM we execute the task with the shortest relative deadline first. Hence, it is also a preemptive algorithm.</p>
<h3 id="response-time-analysis">Response Time Analysis</h3>
<p>Since the approach for measuring utilization (with the formula from RM that sums the utilization of tasks) is too pessimistic to show if a task set is schedulable under DM, we need to use the response time analysis that focuses on the critical instances of tasks (as this shows the worst case scenario). We assume that the task indexes are ordered in increasing relative deadline order, then we can compute th longest response time with $T_i=C_i + I_i$ with $C_i$ computation time and $I_i$ being the interference from higher priority tasks. We then show that it is schedulable by $R_i \leq D_i$.</p>
<h4 id="computing-interference">Computing Interference</h4>
<p>We compute the worst case response time (WCRT) with interference of task $T_k$ on $T_i$ in the interval from $[0,R_i]$ as</p>
<p>$$I_{ik}=\lceil \frac{R_i}{T_k}\rceil C_k$$</p>
<p>Similarly, we do this for all higher priority tasks as</p>
<p>$$I_i=\sum_{k=1}^{i-1}\lceil \frac{R_i}{T_k}\rceil C_k$$</p>
<p>However, this requires the response time ($R_i$) which was to goal to be calculated (we need the interference to calculate the response time but also the response time to calculate the interference). To solve this we make assumptions on the value of the response (since it&rsquo;s on both sides of the equation), calculate the interference based on it, and change the assumption until we reached a fixed point (reach convergence).</p>
<p><img src="/images/IN4343/WCRT_Example.png" alt="WCRT Example"></p>
<h2 id="dynamic-scheduling-policies">Dynamic Scheduling Policies</h2>
<p>Instead a constant priority assignment for each task, we now assign priorities to each job on its release using EDF.</p>
]]></content></item><item><title>Scheduling Aperiodic Tasks</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-aperiodic-tasks/</link><pubDate>Sat, 19 Feb 2022 14:33:05 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/scheduling-aperiodic-tasks/</guid><description>Earliest Due Date (EDD) With this algorithm, we select the task with the earliest relative deadline to run first. However, the system assumes that all tasks arrive simultaneously, hence it knows all deadlines, and preemption is not used. The resulting performance is to minimize the maximum lateness.
Optimality Based on this, if we continue swapping, we end up with the plan that minimizes that maximum lateness. Overall, EDD takes $O(n\text{log}n)$ for queue ordering.</description><content type="html"><![CDATA[<h2 id="earliest-due-date-edd">Earliest Due Date (EDD)</h2>
<p>With this algorithm, we select the task with the earliest <strong>relative</strong> deadline to run first. However, the system assumes that all tasks arrive simultaneously, hence it knows all deadlines, and preemption is not used. The resulting performance is to minimize the maximum lateness.</p>
<h3 id="optimality">Optimality</h3>
<p><img src="/images/IN4343/edd-optimality-1.png" alt="EDD Optimality 1"></p>
<p>Based on this, if we continue swapping, we end up with the plan that minimizes that maximum lateness. Overall, EDD takes $O(n\text{log}n)$ for queue ordering.</p>
<h2 id="earliest-deadline-first-edf">Earliest Deadline First (EDF)</h2>
<p>With this algorithm we use the earliest absolute deadline. Now the tasks can arrive at any time, and we use preemption (assuming no overheads for switching). It again minimizes the maximum lateness. So the schedule checks each time a new task arrives, if it should be scheduled.</p>
<p>Optimality is shown by turning a feasible schedule to an EDF schedule. For this we essentially just iterate through the tasks and check if that has the earliest deadline, if not we swap it with the task that has the earliest deadline.</p>
<p><img src="/images/IN4343/edf_optimality.png" alt="EDF Optimality"></p>
<p>EDF requires $O(n)$ to insert a task in the queue.</p>
<h2 id="non-preemptive-scheduling">Non-Preemptive Scheduling</h2>
<p>It becomes more difficult now if we cannot preempt tasks, but tasks arrive asynchronously. This is because if one task runs a longer time, and another with a short deadline arrives, the long running cannot be interrupted to have the other run, possibly causing the shorter one to miss its deadline.</p>
<p>Given the construction of all possible schedules in a tree, the complexity for finding a feasible solution is $O(nn!)$ with $n!$ leaves and $n$ depth of the tree.</p>
<p>To improve it we can prune the tree if a feasible schedule is found or the addition of a node to the current schedule causes deadline misses. However, this still leads to bad worst case time complexity.</p>
<p>Therefore, we can use a heuristical approach. This selects the step to take at any level by minimizing an optimization function (custom function that can put different weight on variables, e.g. constraints, and minimizes the resulting value). If the leaf contains a infeasible schedule, we go back one level and go to the second best option.</p>
<p><img src="/images/IN4343/np-schedule-optimization.png" alt="Non-Preemptive Scheduling Optimization"></p>
<p>precedence constraints are then handled by assigning the appropriate weights to the heuristical function.</p>
<h2 id="latest-deadline-first-ldf">Latest Deadline First (LDF)</h2>
<p>This algorithm makes use of the precedence graph (DAG) based off which it constructs the schedule. It solves it in polynomial time on the number of tasks and minimizes the maximum lateness. It works by taking the DAG, constructing from the tail of it, and for tasks with no successor (or already selected ones) it takes the task with the latest deadline to execute last. Then, at runtime it takes the head of the queue to execute first.
Start with the leaf nodes that have no children (no task dependency beyond themselves) and place the ones with largest absolute deadline at the head of the queue. This constructs a heap where the tasks with dependencies and later deadlines are further in the heap. <strong>Important here that first means first on heap, such that it is at the bottom and hence last to be executed</strong></p>
<p><img src="/images/IN4343/ldf.png" alt="LDF"></p>
<h2 id="scheduling-with-precedence-constraints-edf">Scheduling with Precedence Constraints (EDF*)</h2>
<p>With this algorithm, it is required to know the arrival times in advance, and then construct a task set that is equivalent but has no precedence constraints, on which we then apply EDF. This transformation requires to postpone the arrival time of successors and advance the deadlines of predecessors (not their real deadlines but the one the system uses to transform).</p>
<p>Transformations are as follows, where $k$ depicts the predecessors of a task.</p>
<p><img src="/images/IN4343/edf_star.png" alt="EDF Star"></p>
<h2 id="aperiodic-scheduling-algorithms-summary">Aperiodic Scheduling Algorithms Summary</h2>
<p><img src="/images/IN4343/aperiodic_scheduling_overview.png" alt="Aperiodic Scheduling Algorithms Overview"></p>
]]></content></item><item><title>Modeling Part 2</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-2/</link><pubDate>Tue, 15 Feb 2022 16:29:20 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-2/</guid><description>Scheduling Problem Given a set of tasks, a set of processors, a set of resources, and a performance objective, the goal is to find assignments for the processors and resources to the tasks such that it results in a maximum-value schedule under the constraints.
Common definitions used are $\sigma$ for the schedule and $\Gamma$ for the tasks, and $A$ for the algorithm that generates the schedule.
The scheduling problem is shown to be NP-Hard (non-deterministic polynomial), meaning that finding a feasible schedule grows exponentially with the number of tasks for the schedule.</description><content type="html"><![CDATA[<h2 id="scheduling-problem">Scheduling Problem</h2>
<p>Given a set of tasks, a set of processors, a set of resources, and a performance objective, the goal is to find assignments for the processors and resources to the tasks such that it results in a <strong>maximum-value</strong> schedule under the constraints.</p>
<p>Common definitions used are $\sigma$ for the schedule and $\Gamma$ for the tasks, and $A$ for the algorithm that generates the schedule.</p>
<p>The scheduling problem is shown to be NP-Hard (non-deterministic polynomial), meaning that finding a feasible schedule grows exponentially with the number of tasks for the schedule.</p>
<h2 id="computational-complexity">Computational Complexity</h2>
<p>We are mainly interested in the execution time that the algorithm needs to finish, including doing the computations. Therefore, we take the worst case execution time of a larger problem (since these show worst case much better than small problems) and compare using the Big-O notation. Then an algorithm is in <strong>polynomial time</strong> if it has a time complexity of the number of tasks to some exponent, specifically $T(n)=O(n^a), a&gt;1$.</p>
<h2 id="taxonomy-of-algorithms">Taxonomy of Algorithms</h2>
<h3 id="preemptive-vs-non-preemptive">Preemptive vs. Non-Preemptive</h3>
<p>These are based on if the tasks can be interrupted (and restored or restarted afterwards).</p>
<h3 id="static-vs-dynamic">Static vs. Dynamic</h3>
<p>Static scheduling is based on fixed parameters that are assigned to the tasks prior to the creation of a task. Dynamic on the other hand is where these parameters might change at runtime.</p>
<h3 id="online-vs-offline">Online vs. Offline</h3>
<p>With online scheduling the schedule is created in the beginning or at the arrival of a new task. Offline scheduling uses a pre-determined table driven schedule, which we can only run if we know what tasks will arrive in the future.</p>
<h3 id="optimal-vs-heuristic">Optimal vs. Heuristic</h3>
<p>Optimal maximizes the value of the performance criteria. Heuristic uses a heuristical approach to maximize, however this will not be optimal.</p>
<h3 id="admission-control">Admission Control</h3>
<p>This tells a task whether it is accepted or rejected. This is necessary to avoid the domino effect of failed jobs. For instance, we have a job that is running, it gets interrupted by a higher priority one, this happens again a couple of times until we have one job that finishes before its deadline. Then continuing the interrupted jobs (in order of highest priority to lowest) will often mean that each of them will finish after their deadline.</p>
<p><img src="/images/IN4343/admission_control.png" alt="Admission Control"></p>
<h2 id="optimal-criteria">Optimal Criteria</h2>
<p>Upon what criteria do we optimize? We need to ensure the schedule is feasible (if there is one), minimize the maximum lateness or deadline misses, maximize the cumulative value of the tasks run, and include the cost for consuming resources.</p>
<p><img src="/images/IN4343/optimal_criteria.png" alt="Optimal Criteria"></p>
<h2 id="grahams-notation">Graham&rsquo;s Notation</h2>
<p>This notation is used to systematically describe the problem and algorithm.</p>
<p><img src="/images/IN4343/graham_notion.png" alt="Graham&rsquo;s Notion"></p>
]]></content></item><item><title>Modeling Part 1</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-1/</link><pubDate>Fri, 11 Feb 2022 14:01:01 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/modeling-part-1/</guid><description>The goal of modeling is to
abstract away the system components (hardware and software) establish assumptions, parameters for model description, variables to use, and understand the constraints on the system define the metrics upon which to optimize the system (performance/cost) Tasks A task is defined as a sequence of instructions (e.g. the code to execute) which is run by the processor until it&amp;rsquo;s finished. We then have the activation time that depicts the time the task is created, the start time for the time the task starts running, the computation time, and the finishing time.</description><content type="html"><![CDATA[<p>The goal of modeling is to</p>
<ul>
<li>abstract away the system components (hardware and software)</li>
<li>establish assumptions, parameters for model description, variables to use, and understand the constraints on the system</li>
<li>define the metrics upon which to optimize the system (performance/cost)</li>
</ul>
<h2 id="tasks">Tasks</h2>
<p>A task is defined as a sequence of instructions (e.g. the code to execute) which is run by the processor until it&rsquo;s finished. We then have the <strong>activation time</strong> that depicts the time the task is created, the <strong>start time</strong> for the time the task starts running, the <strong>computation time</strong>, and the <strong>finishing time</strong>.</p>
<p>Additionally, the <strong>execution time</strong> is given as $f_i - s_i$ with finishing time $f_i$ and start time $s_i$ for the specific task. <strong>response time</strong> is given as $f_i-a_i$ with $a_i$ arrival time for the task.</p>
<h2 id="ready-queue">Ready Queue</h2>
<p>In concurrent systems there can be several tasks that are in the active state, but only one is actually being executed at any point in time. Therefore, such active tasks that are not currently running are in the <strong>ready</strong> state. We then also have a <strong>ready queue</strong> in which the tasks in a ready state are being queued. The scheduling policy then decides how to dispatch the tasks from the ready queue (e.g. FIFO, priority based, LIFO, etc.).</p>
<p>If the system supports <strong>preemption</strong> tasks can be interrupted when another tasks with higher priority needs to be run (e.g. store task states, run higher priority one, restore prior task states once high priority one is done). However, this means that the task is placed again into the ready queue.</p>
<h2 id="task-states">Task States</h2>
<p>Tasks can be in the <strong>idle state</strong> or a <strong>blocked state</strong> as well, where in the idle state they do not do any work and rather are waiting for the next period, and in the blocked state they are waiting for a signal (e.g. with shared memory wait to receive signal that it&rsquo;s safe to access the memory).</p>
<h2 id="definitions">Definitions</h2>
<p><img src="/images/IN4343/deadline.png" alt="Definition"></p>
<p>A RT task is then called <strong>feasible</strong> when it completes before the absolute deadline $f_i \leq d_i$ or $R-I \leq D_i$. <strong>Schedulable</strong> then means that there exists an algorithm that can produce a feasible schedule.</p>
<p>Absolute deadline is given as $d_I$ and the relative deadline as $D_i$.</p>
<p>We have additional timing constraints <img src="/images/IN4343/timing_constraints.png" alt="Timing Constraints">. Also worth mentioning is that jobs are task instances. A task specifies something to do and a job is then an instance of doing that task, meaning multiple jobs of a task can exist.</p>
<h3 id="types-of-tasks">Types of Tasks</h3>
<ul>
<li><strong>Periodic Tasks</strong> These tasks are instantiated automatically every given time frame (their period). We can further classify <strong>single rate</strong> when tasks in the system all have the exact same period, and <strong>multi-rate</strong> where tasks have different periods.</li>
<li><strong>Aperiodic Tasks</strong> These tasks are the opposite and happen at no given time interval but rather depending on things such as external events or interrupts. Aperiodic tasks can be further classified into <strong>unbounded arrival time</strong> or <strong>event based</strong> triggering of tasks and <strong>sporadic tasks</strong> for which there is a minimum gap between arrivals (we don&rsquo;t know the exact arrival rate but at at least 8seconds elapse before any new task can arrive).</li>
</ul>
<h3 id="periodic-tasks">Periodic Tasks</h3>
<p>For periodic tasks we can then calculate the utilization as, with $C_i$ computation time and $T_i$ the task period</p>
<p>$$U_i=\frac{C_i}{T_i}$$</p>
<p>$\phi$ depicts the phase of the instance (its release time).</p>
<p><img src="/images/IN4343/phase.png" alt="phase"></p>
<h3 id="computation-time">Computation Time</h3>
<p>We can estimate the computation time using experiments of prior runs and taking their runtimes, however this fails to account for all real world scenarios, therefore we have several different execution time estimations,</p>
<p><img src="/images/IN4343/computation_time.png" alt="Computation Time"></p>
<p>Setting the safety margin factors in on the predictability (are we guaranteed to fall into the margin if it is large enough) and efficiency (if the margin is too large we are wasting resources).</p>
<h3 id="jitter">Jitter</h3>
<p>The jitter measures the variation in time for a periodic event, given as</p>
<p><img src="/images/IN4343/jitter.png" alt="Jitter"></p>
<h3 id="timing-constraints">Timing Constraints</h3>
<p>The timing constraints give bounds on the timings within the systems (e.g. minimum completion time, maximum allowed jitter, etc.). Often implicit timing constraints need to be met in order for the system to function correctly, whereas explicit timing constraints are specified for the system.</p>
<h4 id="minimum-sampling-period">Minimum Sampling Period</h4>
<p>Guarantees that the system is not overloaded using, where $U_{other}$ depicts the sum over all other tasks $\sum_{i \ne s}^{i} \frac{C_i}{T_i}$</p>
<p><img src="/images/IN4343/msp.png" alt="Minimum Sampling Period"></p>
<h3 id="maximum-sampling-period">Maximum Sampling Period</h3>
<p>Applies the same logic but rather uses the worst-case timings.</p>
<h3 id="precedence-constraints">Precedence Constraints</h3>
<p>Often tasks need to run only after some other task has completed (they require that this other task has run prior to them running), giving us some precedence constraints on the tasks, which is represented using a directed acyclic graph. The graph represents immediate predecessors (need to run just before the task, e.g. task 3 can only run after task 2) and predecessors (need to run before but not directly before, e.g. task 1 needs to run before task 2 and task 2 needs to run before task 3, hence task 1 is predecessor to task 3).</p>
<p>Such graphs can then also represent <strong>fork nodes</strong> points at which multiple tasks can start once a single task has completed and <strong>join nodes</strong> which are tasks that require multiple tasks having completed. We also have <strong>switch nodes</strong> that based on a decision have multiple tasks run (but not all their child nodes) and similarly <strong>if-then nodes</strong> that have the same but just two child nodes of which one runs.</p>
]]></content></item><item><title>Introduction</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/introduction/</link><pubDate>Tue, 08 Feb 2022 10:22:07 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/introduction/</guid><description>What is a Real-Time system? Real-Time systems are the systems that depend on their output (e.g. decisions from computations) and on the time in which these were produced. For example, airplanes will have many smaller systems that produce some result that is required to happen within some time frame (e.g. getting the airplane speed every couple of seconds). Therefore, the computations in Real-Time systems must be performed within a certain timing constraint.</description><content type="html"><![CDATA[<h2 id="what-is-a-real-time-system">What is a Real-Time system?</h2>
<p>Real-Time systems are the systems that depend on their output (e.g. decisions from computations) and on the time in which these were produced. For example, airplanes will have many smaller systems that produce some result that is required to happen within some time frame (e.g. getting the airplane speed every couple of seconds). Therefore, the computations in Real-Time systems must be performed within a certain <strong>timing constraint</strong>. Additionally, the system has to provide <em>bounded response times</em> for the computation under all possible scenarios, such that response times can be predicted for any possible input.</p>
<p>For real-time systems, often the computations are related to its environment (like the airplane example), and operations are adapted to this environment.</p>
<h2 id="classes-of-real-time-tasks">Classes of Real-Time Tasks</h2>
<ul>
<li><strong>Hard</strong> Real Time: the system has to generate a response before the deadline (e.g. safety critical systems).</li>
<li><strong>Soft</strong> Real Time: the system does not have to meet the deadline all the time, some misses are fine (e.g. keyboard I/O can sometimes lag).</li>
<li><strong>Firm</strong> Real Time: similar to Soft real time but now there is no benefit for completing computations after the deadline, results are useless after that point.</li>
</ul>
<h2 id="properties--requirements-of-real-time-systems">Properties &amp; Requirements of Real-Time Systems</h2>
<ul>
<li>Often resources are limited, therefore high efficiency in resource management is required.</li>
<li>If resources are shared, there has to be some temporal isolation to avoid tasks interfering.</li>
<li>As these systems often interact with the environment, they have to have predictable results and required time to produce these.</li>
<li>Tasks can also be very different, therefore the system has to be able to adapt and handle these, as well as being able to handle overloads at times.</li>
</ul>
<h2 id="classes-of-control-systems">Classes of Control Systems</h2>
<p>With real-time systems, as stated before, there is most commonly an object being controller. This object is then called the controlled object (the system), where the real-time system is the controller (doing the computations for changes), and the operator is the environment.</p>
<h3 id="open-loop-control-system">Open-Loop Control System</h3>
<p>In these systems the feedback from the actions are loosely dependent on the environment and there is no feedback from the controlled object to the environment.</p>
<h3 id="closed-loop-control-system">Closed-Loop Control System</h3>
<p>In these, there exists frequent interaction between the system and the environment. Therefore, feedback is going from the environment to the system and from the system to the controller. This often happens at a sampling rate, depending on the use case.</p>
<h3 id="multi-level-feedback-system">Multi-Level Feedback System</h3>
<p>Here feedback is generated for different systems, of the larger system, at different rates. For example in the airplane, the airspeed may be collected every couple of seconds, and the altitude as well, but the autopilot checks all these and others every half a second.</p>
<h2 id="taxonomy-of-real-time-systems">Taxonomy of Real-Time Systems</h2>
<p><strong>Static</strong> analysis can be done at compile time, this implies that duration of tasks is know, and therefore we can tell what the Worst Case Execution Time (WCET) is. However, this is only possible for static systems, and very simple dynamic systems.</p>
<p>We can then also have systems that have a know task duration (either single or multiple durations but all known) which implies that it is a <strong>periodic</strong> system. On the contrary, if we do not know this, it is called an <strong>aperiodic</strong> or sporadic system. These create dynamic situations (e.g. autonomous cars).</p>
]]></content></item><item><title>Info</title><link>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/info/</link><pubDate>Tue, 08 Feb 2022 10:21:30 +0100</pubDate><guid>https://nicktehrany.github.io/notes/in4343-real-time-systems/content/info/</guid><description>IN4343 Real Time Systems: Studyguide: https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;amp;_NotifyTextSearch_
Book: Hard Real-Time COmputing Systems: Predictable Scheduling Algorithms and Applications Third Edition
All content and images are based on and retrieved from the lecture slides and/or the previously mentioned book and/or any other content that is provided in the course.
Authors Nick Tehrany</description><content type="html"><![CDATA[<h2 id="in4343-real-time-systems">IN4343 Real Time Systems:</h2>
<p>Studyguide: <a href="https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;_NotifyTextSearch_">https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=57386&amp;_NotifyTextSearch_</a></p>
<p>Book: Hard Real-Time COmputing Systems: Predictable Scheduling Algorithms and Applications Third Edition</p>
<p>All content and images are based on and retrieved from the lecture slides and/or the previously mentioned book and/or any
other content that is provided in the course.</p>
<h3 id="authors">Authors</h3>
<ul>
<li><a href="https://github.com/nicktehrany">Nick Tehrany</a></li>
</ul>
]]></content></item></channel></rss>